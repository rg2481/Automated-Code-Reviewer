{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kagglehub pandas transformers openai langchain fastapi uvicorn streamlit gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "# Download the latest version\n",
    "path = kagglehub.dataset_download(\"veeralakrishna/python-code-data\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Assuming the dataset is a ZIP file\n",
    "dataset_zip = f\"{path}/python-code-data.zip\"\n",
    "\n",
    "if os.path.exists(dataset_zip):\n",
    "    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path)\n",
    "    print(\"Dataset extracted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Get a list of all TXT files in the dataset folder\n",
    "txt_files = glob.glob(f\"{path}/*.txt\")\n",
    "\n",
    "# Read and print the first few lines of each file\n",
    "for file in txt_files:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        print(f\"Contents of {file}:\")\n",
    "        print(f.read()[:500])  # Read only the first 500 characters for preview\n",
    "        print(\"\\n\" + \"-\" * 80 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "# Read each text file and store its content in a list\n",
    "for file in txt_files:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "        data.append({\"filename\": os.path.basename(file), \"code\": content})\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(df.head())  # Display first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def check_syntax(code_snippet):\n",
    "    try:\n",
    "        ast.parse(code_snippet)\n",
    "        return \"‚úÖ No syntax errors found.\"\n",
    "    except SyntaxError as e:\n",
    "        return f\"‚ùå Syntax Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "try:\n",
    "    models = openai.models.list()\n",
    "    available_models = [model.id for model in models.data]\n",
    "    print(\"Available models:\", available_models)\n",
    "except openai.OpenAIError as e:\n",
    "    print(\"‚ùå OpenAI API error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def ai_code_review(code_snippet):\n",
    "    prompt = f\"Review this Python code and suggest improvements:\\n\\n{code_snippet}\"\n",
    "    \n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-4o\",  # ‚úÖ Most powerful model\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except openai.RateLimitError:\n",
    "        print(\"Rate limit reached. Waiting 10 seconds before retrying...\")\n",
    "        time.sleep(10)  # Wait before retrying\n",
    "        return ai_code_review(code_snippet)\n",
    "\n",
    "# Example usage\n",
    "code_example = \"def add(x, y):\\n    return x + y\"\n",
    "print(ai_code_review(code_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load CodeGen model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-2B-multi\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-2B-multi\")\n",
    "\n",
    "def generate_code_review(code_snippet):\n",
    "    input_ids = tokenizer(code_snippet, return_tensors=\"pt\").input_ids\n",
    "    output = model.generate(input_ids, max_length=256)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(generate_code_review(code_example))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_pipeline(code_snippet):\n",
    "    syntax_review = check_syntax(code_snippet)\n",
    "    ai_review = ai_code_review(code_snippet)\n",
    "    return f\"{syntax_review}\\n\\nAI Review:\\n{ai_review}\"\n",
    "\n",
    "print(review_pipeline(\"def add(x, y)\\n    return x + y\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "\n",
    "st.title(\"üöÄ Automated Code Reviewer\")\n",
    "\n",
    "code = st.text_area(\"Paste your Python code here:\")\n",
    "\n",
    "if st.button(\"Review Code\"):\n",
    "    review = review_pipeline(code)\n",
    "    st.text_area(\"Review Results:\", review, height=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class CodeInput(BaseModel):\n",
    "    code: str\n",
    "\n",
    "@app.post(\"/review\")\n",
    "def review_code_api(data: CodeInput):\n",
    "    return {\"review\": review_pipeline(data.code)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
